
#user  nobody;
worker_processes  1;

#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

#pid        logs/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       mime.types;
    default_type  application/octet-stream;

    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';

    #access_log  logs/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    #gzip  on;



    # Load Balancing 
   #####################################
   # upstream for load balancing 

   upstream api4_Cluster {
    # stick sessions ... https://www.imperva.com/learn/availability/sticky-session-persistence-and-cookies/#:~:text=Session%20stickiness%2C%20a.k.a.%2C%20session%20persistence,IP%20spends%20on%20a%20website).
    #  ip_hash; 
    # we set it her for using stick sessions


   # If one server is more powerful than another, you should make it handle a larger number of requests.
   # To do this, add a higher weighting to that server.
   # server with port 6002 is more powerfull than server with port 6001 
   server localhost:6001 weight=10; # serve api4 requests
   server localhost:6002 weight=20 max_fails=2 fail_timeout=5s; # serve api4 requests

   # max_fails=number
   # sets the number of unsuccessful attempts to communicate with the server that should happen in the duration set by the fail_timeout parameter 
   #to consider the server unavailable for a duration also set by the fail_timeout parameter.

   # backup
   #--------------------------
   # marks the server as a backup server. It will be passed requests when the primary servers are unavailable.
   # The parameter cannot be used along with the hash, ip_hash, and random load balancing methods.

   # If one of the upstream servers in an Nginx load balanced environment goes offline, it can be marked as down in the config file.
   # If an upstream server is marked as being down, the Nginx load balancer will not forward any requests to that server until the flag is removed. 
  server localhost:6003 down;

  }


# Or /api4 servers coould be on different server same port like this :
#upstream  api4_Cluster  {
#  server   api4_1.example.com:8080          max_fails=3  fail_timeout=30s;
#  server   api4_2.example.com:8080          max_fails=3  fail_timeout=30s;
#  server   api4_3.example.com:8080          max_fails=3  fail_timeout=30s;
#}






    server {
    # app server on port 3000/4000/5000
    # nginx listens on port 8070

    listen 8070;
    listen [::]:8070;
    server_name yourdomain.example;

    location ^~ /api1/{
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Host $http_host;
        proxy_set_header X-NginX-Proxy true;
        proxy_pass    http://127.0.0.1:3000/;
    }
    
    location ^~ /api2/{
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Host $http_host;
        proxy_set_header X-NginX-Proxy true;
        proxy_pass    http://127.0.0.1:4000/;
    }

    location ^~ /api3/{
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Host $http_host;
        proxy_set_header X-NginX-Proxy true;
        proxy_pass    http://127.0.0.1:5000/;
    } 



 # Load Balancing Example on /api4
 # we have three servers that serve /api4 requests
#####################################
    
    location /api4/{ 
    # or location ^~ /api4/{
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Host $http_host;
        proxy_set_header X-NginX-Proxy true;

        # any requests for http://localhost:8070/api4 will be redirected to :
        proxy_pass    http://api4_Cluster;

        # api4_Cluster; could be localhost:6001 or localhost:6002 
        # that depends on Load balancer choise for every request 

        # note : that proxy_pass value and upsream defintion have the same name
        # upstream api4_Cluster { .... }
    }
  
     


    # Serving Static Assets
 ##################################

location / {
    try_files $uri $uri/ =404;
  }

  # The proxy_pass setting will also make the
  # Nginx load balancer a reverse proxy
  location /sample {
    proxy_pass http://www.antrados.com/;
  }



  location /RGBGame/ {
     alias /var/www/RGBGame/;
  }

 # ** When using alias a request to domain.com/RGBGame/file.foo will serve files from: 
 # **   /var/www/RGBGame/file.foo


 # ** You could use root for example (here we append the location to the path):
 
  # location /RGBGame/
  # path /var/www/khairulslt.me/
 # location /RGBGame/ { 
 #    root /var/www/khairulslt.me/;
 # }
   
 # ** In this case, requests to domain.com/RGBGame/file.foo will serve files from: 
  # /var/www/domain.com/RGBGame/file.foo

  #  location /public {
       # root /usr/local/var/www;  
  #  }
  #  location /RGBGame/ {
      # alias /var/www/RGBGame/;
 #   }
  #  location /RGBGame2/ {
  #   # root /var/www/domain.com/;
  #   }
}

}
